{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izYxxJmNf7Vg"
      },
      "outputs": [],
      "source": [
        "1. Write a Python script to visualize the distribution of errors (residuals) for a multiple linear regression model\n",
        "using Seaborn's \"diamonds\"Â dataset.\n",
        "\n",
        "# Import necessary libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "# Load the diamonds dataset\n",
        "diamonds = sns.load_dataset('diamonds')\n",
        "\n",
        "# Fit the multiple linear regression model\n",
        "model = ols('price ~ carat + depth + table', data=diamonds).fit()\n",
        "\n",
        "# Calculate residuals\n",
        "residuals = model.resid\n",
        "\n",
        "# Create a DataFrame with residuals\n",
        "residuals_df = diamonds[['carat', 'depth', 'table']].copy()\n",
        "residuals_df['residuals'] = residuals\n",
        "\n",
        "# Visualize the distribution of residuals\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(residuals, kde=True)\n",
        "plt.title('Distribution of Residuals')\n",
        "plt.xlabel('Residual Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# Visualize residuals vs. fitted values\n",
        "fitted_values = model.fittedvalues\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x=fitted_values, y=residuals)\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.title('Residuals vs. Fitted Values')\n",
        "plt.xlabel('Fitted Value')\n",
        "plt.ylabel('Residual')\n",
        "plt.show()\n",
        "\n",
        "# Visualize residuals vs. independent variables\n",
        "for column in ['carat', 'depth', 'table']:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.scatterplot(x=diamonds[column], y=residuals)\n",
        "    plt.axhline(y=0, color='r', linestyle='--')\n",
        "    plt.title(f'Residuals vs. {column}')\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel('Residual')\n",
        "    plt.show()\n",
        "\n",
        "2. Write a Python script to calculate and print Mean Squared Error (MSE), Mean Absolute Error (MAE), and Root\n",
        "Mean Squared Error (RMSE) for a linear regression model.\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import math\n",
        "\n",
        "# Generate sample data\n",
        "np.random.seed(0)\n",
        "X = 2 * np.random.rand(100, 1)\n",
        "y = 4 + 3 * X + np.random.randn(100, 1)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate MSE, MAE, and RMSE\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = math.sqrt(mse)\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "\n",
        "3.  Write a Python script to check if the assumptions of linear regression are met. Use a scatter plot to check\n",
        "linearity, residuals plot for homoscedasticity, and correlation matrix for multicollinearity.\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Generate sample data\n",
        "np.random.seed(0)\n",
        "X1 = np.random.rand(100)\n",
        "X2 = np.random.rand(100)\n",
        "y = 3 + 2 * X1 + np.random.randn(100)\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({'X1': X1, 'X2': X2, 'y': y})\n",
        "\n",
        "# Scatter plot to check linearity\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x='X1', y='y', data=df)\n",
        "plt.title('Scatter Plot of X1 vs. y')\n",
        "plt.show()\n",
        "\n",
        "# Fit the linear regression model\n",
        "X = df[['X1', 'X2']]\n",
        "y = df['y']\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Calculate residuals\n",
        "y_pred = model.predict(X)\n",
        "residuals = y - y_pred\n",
        "\n",
        "# Residuals plot to check homoscedasticity\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x=y_pred, y=residuals)\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.title('Residuals vs. Fitted Values')\n",
        "plt.xlabel('Fitted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.show()\n",
        "\n",
        "# Correlation matrix to check multicollinearity\n",
        "corr_matrix = df[['X1', 'X2']].corr()\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', square=True)\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()\n",
        "\n",
        "4.  Write a Python script that creates a machine learning pipeline with feature scaling and evaluates the\n",
        "performance of different regression models\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Generate sample data\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 3)\n",
        "y = 3 + 2 * X[:, 0] + np.random.randn(100)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define regression models\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Random Forest Regressor': RandomForestRegressor(),\n",
        "    'Support Vector Regressor': SVR()\n",
        "}\n",
        "\n",
        "# Create a pipeline with feature scaling\n",
        "for name, model in models.items():\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', model)\n",
        "    ])\n",
        "\n",
        "    # Train the pipeline\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Print the results\n",
        "    print(f\"Model: {name}\")\n",
        "    print(f\"MSE: {mse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}\")\n",
        "    print()\n",
        "\n",
        "\n",
        "5. Implement a simple linear regression model on a dataset and print the model's coefficients, intercept, and\n",
        "R-squared score.\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate sample data\n",
        "np.random.seed(0)\n",
        "X = 2 * np.random.rand(100, 1)\n",
        "y = 4 + 3 * X + np.random.randn(100, 1)\n",
        "\n",
        "# Create and fit the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Get the model's coefficients and intercept\n",
        "coefficient = model.coef_[0][0]\n",
        "intercept = model.intercept_[0]\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Calculate the R-squared score\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "# Print the model's coefficients, intercept, and R-squared score\n",
        "print(f\"Coefficient: {coefficient:.4f}\")\n",
        "print(f\"Intercept: {intercept:.4f}\")\n",
        "print(f\"R-squared Score: {r2:.4f}\")\n",
        "\n",
        "# Plot the data and the regression line\n",
        "plt.scatter(X, y, label='Data')\n",
        "plt.plot(X, y_pred, color='red', label='Regression Line')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "6. Write a Python script that analyzes the relationship between total bill and tip in the 'tips' dataset using\n",
        "simple linear regression and visualizes the results.\n",
        "\n",
        "# Import necessary libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Load the tips dataset\n",
        "tips = sns.load_dataset('tips')\n",
        "\n",
        "# Define the independent and dependent variables\n",
        "X = tips[['total_bill']]\n",
        "y = tips['tip']\n",
        "\n",
        "# Create and fit the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Get the model's coefficient and intercept\n",
        "coefficient = model.coef_[0]\n",
        "intercept = model.intercept_\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Plot the data and the regression line\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X['total_bill'], y, label='Data')\n",
        "plt.plot(X['total_bill'], y_pred, color='red', label='Regression Line')\n",
        "plt.xlabel('Total Bill ($)')\n",
        "plt.ylabel('Tip ($)')\n",
        "plt.title('Relationship between Total Bill and Tip')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Print the model's coefficient and intercept\n",
        "print(f\"Coefficient: {coefficient:.4f}\")\n",
        "print(f\"Intercept: {intercept:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "7. Write a Python script that fits a linear regression model to a synthetic dataset with one feature. Use the\n",
        "model to predict new values and plot the data points along with the regression line.\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Generate synthetic dataset\n",
        "np.random.seed(0)\n",
        "X = 2 * np.random.rand(100, 1)\n",
        "y = 4 + 3 * X + np.random.randn(100, 1)\n",
        "\n",
        "# Create and fit the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Get the model's coefficient and intercept\n",
        "coefficient = model.coef_[0][0]\n",
        "intercept = model.intercept_[0]\n",
        "\n",
        "# Print the model's coefficient and intercept\n",
        "print(f\"Coefficient: {coefficient:.4f}\")\n",
        "print(f\"Intercept: {intercept:.4f}\")\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Plot the data points and the regression line\n",
        "plt.scatter(X, y, label='Data Points')\n",
        "plt.plot(X, y_pred, color='red', label='Regression Line')\n",
        "plt.xlabel('Feature')\n",
        "plt.ylabel('Target Variable')\n",
        "plt.title('Linear Regression')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Predict new values\n",
        "new_X = np.array([[1.5]])\n",
        "new_y_pred = model.predict(new_X)\n",
        "print(f\"Predicted value for X = {new_X[0][0]}: {new_y_pred[0][0]:.4f}\")\n",
        "\n",
        "\n",
        "8. Write a Python script that pickles a trained linear regression model and saves it to a file.\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Generate sample data\n",
        "np.random.seed(0)\n",
        "X = 2 * np.random.rand(100, 1)\n",
        "y = 4 + 3 * X + np.random.randn(100, 1)\n",
        "\n",
        "# Create and fit the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Pickle the trained model and save it to a file\n",
        "with open('linear_regression_model.pkl', 'wb') as file:\n",
        "    pickle.dump(model, file)\n",
        "\n",
        "print(\"Trained linear regression model saved to linear_regression_model.pkl\")\n",
        "\n",
        "\n",
        "9. Write a Python script that fits a polynomial regression model (degree 2) to a dataset and plots the\n",
        "regression curve.\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Generate sample data\n",
        "np.random.seed(0)\n",
        "X = 2 * np.random.rand(100, 1)\n",
        "y = 4 + 3 * X + 2 * X**2 + np.random.randn(100, 1)\n",
        "\n",
        "# Create polynomial features\n",
        "poly_features = PolynomialFeatures(degree=2)\n",
        "X_poly = poly_features.fit_transform(X)\n",
        "\n",
        "# Create and fit the polynomial regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_poly, y)\n",
        "\n",
        "# Get the coefficients\n",
        "coefficient_2 = model.coef_[0][2]\n",
        "coefficient_1 = model.coef_[0][1]\n",
        "intercept = model.intercept_[0]\n",
        "\n",
        "# Print the coefficients\n",
        "print(f\"Coefficient of x^2: {coefficient_2:.4f}\")\n",
        "print(f\"Coefficient of x: {coefficient_1:.4f}\")\n",
        "print(f\"Intercept: {intercept:.4f}\")\n",
        "\n",
        "# Generate data for plotting the regression curve\n",
        "X_test = np.linspace(0, 2, 100).reshape(-1, 1)\n",
        "X_test_poly = poly_features.transform(X_test)\n",
        "y_pred = model.predict(X_test_poly)\n",
        "\n",
        "# Plot the data points and the regression curve\n",
        "plt.scatter(X, y, label='Data Points')\n",
        "plt.plot(X_test, y_pred, color='red', label='Regression Curve')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.title('Polynomial Regression')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "10. Generate synthetic data for simple linear regression (use random values for X and y) and fit a linear\n",
        "regression model to the data. Print the model's coefficient and intercept.\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 1)\n",
        "y = 3 + 2 * X + np.random.randn(100, 1)\n",
        "\n",
        "# Create and fit the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Get the model's coefficient and intercept\n",
        "coefficient = model.coef_[0][0]\n",
        "intercept = model.intercept_[0]\n",
        "\n",
        "# Print the model's coefficient and intercept\n",
        "print(f\"Coefficient: {coefficient:.4f}\")\n",
        "print(f\"Intercept: {intercept:.4f}\")\n",
        "\n",
        "11. Write a Python script that fits polynomial regression models of different degrees to a synthetic dataset and\n",
        "compares their performance.\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Generate synthetic dataset\n",
        "np.random.seed(0)\n",
        "X = 2 * np.random.rand(100, 1)\n",
        "y = 4 + 3 * X + 2 * X**2 + np.random.randn(100, 1)\n",
        "\n",
        "# Define polynomial regression models with different degrees\n",
        "degrees = [1, 2, 3, 4, 5]\n",
        "models = []\n",
        "mse_values = []\n",
        "\n",
        "for degree in degrees:\n",
        "    model = Pipeline([\n",
        "        ('poly_features', PolynomialFeatures(degree=degree)),\n",
        "        ('linear_regression', LinearRegression())\n",
        "    ])\n",
        "    model.fit(X, y)\n",
        "    models.append(model)\n",
        "    y_pred = model.predict(X)\n",
        "    mse = mean_squared_error(y, y_pred)\n",
        "    mse_values.append(mse)\n",
        "    print(f\"Degree: {degree}, MSE: {mse:.4f}\")\n",
        "\n",
        "# Plot the data points and regression curves\n",
        "plt.scatter(X, y, label='Data Points')\n",
        "for degree, model in zip(degrees, models):\n",
        "    X_test = np.linspace(0, 2, 100).reshape(-1, 1)\n",
        "    y_pred = model.predict(X_test)\n",
        "    plt.plot(X_test, y_pred, label=f'Degree {degree}')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.title('Polynomial Regression')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot MSE values\n",
        "plt.plot(degrees, mse_values, marker='o')\n",
        "plt.xlabel('Degree')\n",
        "plt.ylabel('MSE')\n",
        "plt.title('MSE vs Degree')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "12.  Write a Python script that fits a simple linear regression model with two features and prints the model's\n",
        "coefficients, intercept, and R-squared score.\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Generate sample data\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 2)\n",
        "y = 3 + 2 * X[:, 0] + 1.5 * X[:, 1] + np.random.randn(100)\n",
        "\n",
        "# Create and fit the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Get the model's coefficients and intercept\n",
        "coefficients = model.coef_\n",
        "intercept = model.intercept_\n",
        "\n",
        "# Print the model's coefficients and intercept\n",
        "print(f\"Coefficients: {coefficients}\")\n",
        "print(f\"Intercept: {intercept:.4f}\")\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Calculate the R-squared score\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "# Print the R-squared score\n",
        "print(f\"R-squared Score: {r2:.4f}\")\n",
        "\n",
        "\n",
        "13.  Write a Python script that generates synthetic data, fits a linear regression model, and visualizes the\n",
        "regression line along with the data points.\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(0)\n",
        "X = 2 * np.random.rand(100, 1)\n",
        "y = 4 + 3 * X + np.random.randn(100, 1)\n",
        "\n",
        "# Create and fit the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Get the model's coefficient and intercept\n",
        "coefficient = model.coef_[0][0]\n",
        "intercept = model.intercept_[0]\n",
        "\n",
        "# Print the model's coefficient and intercept\n",
        "print(f\"Coefficient: {coefficient:.4f}\")\n",
        "print(f\"Intercept: {intercept:.4f}\")\n",
        "\n",
        "# Generate data for plotting the regression line\n",
        "X_test = np.linspace(0, 2, 100).reshape(-1, 1)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Plot the data points and the regression line\n",
        "plt.scatter(X, y, label='Data Points')\n",
        "plt.plot(X_test, y_pred, color='red', label='Regression Line')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.title('Linear Regression')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "14. Write a Python script that uses the Variance Inflation Factor (VIF) to check for multicollinearity in a dataset\n",
        "with multiple features\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# Generate sample data\n",
        "np.random.seed(0)\n",
        "X1 = np.random.rand(100)\n",
        "X2 = 2 * X1 + np.random.randn(100) * 0.1  # X2 is highly correlated with X1\n",
        "X3 = np.random.rand(100)\n",
        "X = pd.DataFrame({'X1': X1, 'X2': X2, 'X3': X3})\n",
        "\n",
        "# Calculate VIF for each feature\n",
        "vif = pd.DataFrame()\n",
        "vif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "vif[\"features\"] = X.columns\n",
        "\n",
        "# Print the VIF values\n",
        "print(vif)\n",
        "\n",
        "\n",
        "15. Write a Python script that generates synthetic data for a polynomial relationship (degree 4), fits a\n",
        "polynomial regression model, and plots the regression curve.\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(0)\n",
        "X = 2 * np.random.rand(100, 1) - 1  # Generate X values between -1 and 1\n",
        "y = 4 + 3 * X + 2 * X**2 + 1 * X**3 + 0.5 * X**4 + np.random.randn(100, 1)\n",
        "\n",
        "# Create polynomial features\n",
        "poly_features = PolynomialFeatures(degree=4)\n",
        "X_poly = poly_features.fit_transform(X)\n",
        "\n",
        "# Create and fit the polynomial regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_poly, y)\n",
        "\n",
        "# Generate data for plotting the regression curve\n",
        "X_test = np.linspace(-1, 1, 100).reshape(-1, 1)\n",
        "X_test_poly = poly_features.transform(X_test)\n",
        "y_pred = model.predict(X_test_poly)\n",
        "\n",
        "# Plot the data points and the regression curve\n",
        "plt.scatter(X, y, label='Data Points')\n",
        "plt.plot(X_test, y_pred, color='red', label='Regression Curve')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.title('Polynomial Regression')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "16. Write a Python script that creates a machine learning pipeline with data standardization and a multiple\n",
        "linear regression model, and prints the R-squared score.\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Generate sample data\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 3)\n",
        "y = 3 + 2 * X[:, 0] + 1.5 * X[:, 1] + np.random.randn(100)\n",
        "\n",
        "# Create a pipeline with standardization and multiple linear regression\n",
        "pipeline = Pipeline([\n",
        "    ('standardizer', StandardScaler()),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "# Fit the pipeline\n",
        "pipeline.fit(X, y)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = pipeline.predict(X)\n",
        "\n",
        "# Calculate the R-squared score\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "# Print the R-squared score\n",
        "print(f\"R-squared Score: {r2:.4f}\")\n",
        "\n",
        "\n",
        "17. Write a Python script that performs polynomial regression (degree 3) on a synthetic dataset and plots the\n",
        "regression curve\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(0)\n",
        "X = 2 * np.random.rand(100, 1) - 1\n",
        "y = 3 * X**3 + 2 * X**2 + X + np.random.randn(100, 1)\n",
        "\n",
        "# Create polynomial features\n",
        "poly_features = PolynomialFeatures(degree=3)\n",
        "X_poly = poly_features.fit_transform(X)\n",
        "\n",
        "# Create and fit the polynomial regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_poly, y)\n",
        "\n",
        "# Generate data for plotting the regression curve\n",
        "X_test = np.linspace(-1, 1, 100).reshape(-1, 1)\n",
        "X_test_poly = poly_features.transform(X_test)\n",
        "y_pred = model.predict(X_test_poly)\n",
        "\n",
        "# Plot the data points and the regression curve\n",
        "plt.scatter(X, y, label='Data Points')\n",
        "plt.plot(X_test, y_pred, color='red', label='Regression Curve')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.title('Polynomial Regression')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "18. Write a Python script that performs multiple linear regression on a synthetic dataset with 5 features. Print\n",
        "the R-squared score and model coefficients.\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 5)\n",
        "y = 3 + 2 * X[:, 0] + 1.5 * X[:, 1] + 0.5 * X[:, 2] + np.random.randn(100)\n",
        "\n",
        "# Create and fit the multiple linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Get the model coefficients and intercept\n",
        "coefficients = model.coef_\n",
        "intercept = model.intercept_\n",
        "\n",
        "# Print the model coefficients and intercept\n",
        "print(\"Model Coefficients:\")\n",
        "for i, coefficient in enumerate(coefficients):\n",
        "    print(f\"Feature {i+1}: {coefficient:.4f}\")\n",
        "print(f\"Intercept: {intercept:.4f}\")\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Calculate the R-squared score\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "# Print the R-squared score\n",
        "print(f\"R-squared Score: {r2:.4f}\")\n",
        "\n",
        "\n",
        "19.  Write a Python script that generates synthetic data for linear regression, fits a model, and visualizes the\n",
        "data points along with the regression line.\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(0)\n",
        "X = 2 * np.random.rand(100, 1)\n",
        "y = 4 + 3 * X + np.random.randn(100, 1)\n",
        "\n",
        "# Create and fit the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Get the model's coefficient and intercept\n",
        "coefficient = model.coef_[0][0]\n",
        "intercept = model.intercept_[0]\n",
        "\n",
        "# Print the model's coefficient and intercept\n",
        "print(f\"Coefficient: {coefficient:.4f}\")\n",
        "print(f\"Intercept: {intercept:.4f}\")\n",
        "\n",
        "# Generate data for plotting the regression line\n",
        "X_test = np.linspace(0, 2, 100).reshape(-1, 1)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Plot the data points and the regression line\n",
        "plt.scatter(X, y, label='Data Points')\n",
        "plt.plot(X_test, y_pred, color='red', label='Regression Line')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.title('Linear Regression')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "20. Create a synthetic dataset with 3 features and perform multiple linear regression. Print the model's Rsquared score and coefficients.\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 3)\n",
        "y = 3 + 2 * X[:, 0] + 1.5 * X[:, 1] + 0.5 * X[:, 2] + np.random.randn(100)\n",
        "\n",
        "# Create and fit the multiple linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Get the model coefficients and intercept\n",
        "coefficients = model.coef_\n",
        "intercept = model.intercept_\n",
        "\n",
        "# Print the model coefficients and intercept\n",
        "print(\"Model Coefficients:\")\n",
        "for i, coefficient in enumerate(coefficients):\n",
        "    print(f\"Feature {i+1}: {coefficient:.4f}\")\n",
        "print(f\"Intercept: {intercept:.4f}\")\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Calculate the R-squared score\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "# Print the R-squared score\n",
        "print(f\"R-squared Score: {r2:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "21. Write a Python script that demonstrates how to serialize and deserialize machine learning models using\n",
        "joblib instead of pickling\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import joblib\n",
        "\n",
        "# Generate sample data\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 1)\n",
        "y = 3 + 2 * X + np.random.randn(100, 1)\n",
        "\n",
        "# Create and fit the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Serialize the model using joblib\n",
        "joblib.dump(model, 'linear_regression_model.joblib')\n",
        "\n",
        "# Deserialize the model using joblib\n",
        "loaded_model = joblib.load('linear_regression_model.joblib')\n",
        "\n",
        "# Make predictions using the loaded model\n",
        "y_pred = loaded_model.predict(X)\n",
        "\n",
        "# Print the model's coefficient and intercept\n",
        "print(f\"Coefficient: {loaded_model.coef_[0][0]:.4f}\")\n",
        "print(f\"Intercept: {loaded_model.intercept_[0]:.4f}\")\n",
        "\n",
        "\n",
        "22. Write a Python script to perform linear regression with categorical features using one-hot encoding. Use\n",
        "the Seaborn 'tips' dataset.\n",
        "\n",
        "# Import necessary libraries\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the tips dataset\n",
        "tips = sns.load_dataset('tips')\n",
        "\n",
        "# Define features (X) and target variable (y)\n",
        "X = tips[['sex', 'smoker', 'day', 'time']]\n",
        "y = tips['total_bill']\n",
        "\n",
        "# One-hot encode categorical features\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "X_encoded = encoder.fit_transform(X)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and fit the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the mean squared error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "# Print the mean squared error\n",
        "print(f\"Mean Squared Error: {mse:.4f}\")\n",
        "\n",
        "\n",
        "23. Compare Ridge Regression with Linear Regression on a synthetic dataset and print the coefficients and Rsquared score.\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 3)\n",
        "y = 3 + 2 * X[:, 0] + 1.5 * X[:, 1] + 0.5 * X[:, 2] + np.random.randn(100)\n",
        "\n",
        "# Linear Regression\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X, y)\n",
        "y_pred_linear = linear_model.predict(X)\n",
        "\n",
        "# Ridge Regression\n",
        "ridge_model = Ridge(alpha=1.0)\n",
        "ridge_model.fit(X, y)\n",
        "y_pred_ridge = ridge_model.predict(X)\n",
        "\n",
        "# Print coefficients\n",
        "print(\"Linear Regression Coefficients:\")\n",
        "print(linear_model.coef_)\n",
        "print(\"Ridge Regression Coefficients:\")\n",
        "print(ridge_model.coef_)\n",
        "\n",
        "# Calculate R-squared scores\n",
        "r2_linear = r2_score(y, y_pred_linear)\n",
        "r2_ridge = r2_score(y, y_pred_ridge)\n",
        "\n",
        "# Print R-squared scores\n",
        "print(f\"Linear Regression R-squared Score: {r2_linear:.4f}\")\n",
        "print(f\"Ridge Regression R-squared Score: {r2_ridge:.4f}\")\n",
        "\n",
        "\n",
        "24. Write a Python script that uses cross-validation to evaluate a Linear Regression model on a synthetic\n",
        "dataset\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import make_scorer, mean_squared_error\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 3)\n",
        "y = 3 + 2 * X[:, 0] + 1.5 * X[:, 1] + 0.5 * X[:, 2] + np.random.randn(100)\n",
        "\n",
        "# Create a linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Define a scoring function (negative mean squared error)\n",
        "scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
        "\n",
        "# Perform cross-validation\n",
        "scores = cross_val_score(model, X, y, cv=5, scoring=scorer)\n",
        "\n",
        "# Print the cross-validation scores\n",
        "print(\"Cross-Validation Scores:\")\n",
        "print(scores)\n",
        "\n",
        "# Print the mean and standard deviation of the scores\n",
        "print(f\"Mean Score: {-scores.mean():.4f}\")\n",
        "print(f\"Standard Deviation: {scores.std():.4f}\")\n",
        "\n",
        "\n",
        "25. Write a Python script that compares polynomial regression models of different degrees and prints the Rsquared score for each.\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(0)\n",
        "X = 2 * np.random.rand(100, 1) - 1\n",
        "y = 3 * X**3 + 2 * X**2 + X + np.random.randn(100, 1)\n",
        "\n",
        "# Define degrees to compare\n",
        "degrees = [1, 2, 3, 4, 5]\n",
        "\n",
        "# Compare polynomial regression models\n",
        "for degree in degrees:\n",
        "    # Create polynomial features\n",
        "    poly_features = PolynomialFeatures(degree=degree)\n",
        "    X_poly = poly_features.fit_transform(X)\n",
        "\n",
        "    # Create and fit the polynomial regression model\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_poly, y)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_poly)\n",
        "\n",
        "    # Calculate the R-squared score\n",
        "    r2 = r2_score(y, y_pred)\n",
        "\n",
        "    # Print the R-squared score\n",
        "    print(f\"Degree {degree}: R-squared Score = {r2:.4f}\")\n",
        "\n",
        "# Plot the data and regression curves\n",
        "plt.scatter(X, y, label='Data Points')\n",
        "for degree in degrees:\n",
        "    poly_features = PolynomialFeatures(degree=degree)\n",
        "    X_poly = poly_features.fit_transform(X)\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_poly, y)\n",
        "    X_test = np.linspace(-1, 1, 100).reshape(-1, 1)\n",
        "    X_test_poly = poly_features.transform(X_test)\n",
        "    y_pred = model.predict(X_test_poly)\n",
        "    plt.plot(X_test, y_pred, label=f'Degree {degree}')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.title('Polynomial Regression')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ]
}